version: '3.8'

# Production override for docker-compose.yml
# Usage: docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

services:
  # Production API Service
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    restart: unless-stopped
    environment:
      - APP_ENV=production
      - APP_DEBUG=false
      - DB_HOST=database
      - DB_DATABASE=interviews_tv
      - DB_USERNAME=interviews_tv
      - DB_PASSWORD=${DB_PASSWORD}
      - REDIS_HOST=redis
      - CACHE_DRIVER=redis
      - SESSION_DRIVER=redis
      - MAIL_MAILER=smtp
      - MAIL_HOST=${MAIL_HOST}
      - MAIL_PORT=${MAIL_PORT}
      - MAIL_USERNAME=${MAIL_USERNAME}
      - MAIL_PASSWORD=${MAIL_PASSWORD}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      - AWS_BUCKET=${AWS_BUCKET}
    volumes:
      - ./storage/logs:/var/www/html/api/storage/logs
      - ./storage/uploads:/var/www/html/api/storage/uploads
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Production Frontend (Static Files)
  web:
    image: nginx:alpine
    restart: unless-stopped
    volumes:
      - ./web/dist:/usr/share/nginx/html
      - ./docker/nginx/frontend.conf:/etc/nginx/conf.d/default.conf
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  # Production Database with Replication
  database:
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD}
      MYSQL_DATABASE: interviews_tv
      MYSQL_USER: interviews_tv
      MYSQL_PASSWORD: ${DB_PASSWORD}
    volumes:
      - database_data:/var/lib/mysql
      - ./docker/mysql/prod.cnf:/etc/mysql/conf.d/prod.cnf
      - ./backups:/backups
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    command: --default-authentication-plugin=mysql_native_password --innodb-buffer-pool-size=2G

  # Production Redis with Persistence
  redis:
    restart: unless-stopped
    volumes:
      - redis_data:/data
      - ./docker/redis/prod.conf:/usr/local/etc/redis/redis.conf
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
    command: redis-server /usr/local/etc/redis/redis.conf

  # Production Nginx Load Balancer
  nginx:
    restart: unless-stopped
    volumes:
      - ./docker/nginx/prod.conf:/etc/nginx/nginx.conf
      - ./docker/nginx/sites-prod:/etc/nginx/conf.d
      - ./docker/ssl:/etc/nginx/ssl
      - ./web/dist:/var/www/web
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Production Queue Workers
  queue:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    restart: unless-stopped
    environment:
      - APP_ENV=production
      - DB_HOST=database
      - REDIS_HOST=redis
    volumes:
      - ./storage/logs:/var/www/html/api/storage/logs
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    command: php api/artisan queue:work --sleep=3 --tries=3 --max-time=3600

  # Production Scheduler
  scheduler:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    restart: unless-stopped
    environment:
      - APP_ENV=production
      - DB_HOST=database
      - REDIS_HOST=redis
    volumes:
      - ./storage/logs:/var/www/html/api/storage/logs
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M

  # Production Elasticsearch Cluster
  elasticsearch:
    restart: unless-stopped
    environment:
      - cluster.name=interviews-tv-cluster
      - node.name=es-node-1
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # Production Prometheus
  prometheus:
    restart: unless-stopped
    volumes:
      - ./docker/prometheus/prod.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'

  # Production Grafana
  grafana:
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_SECURITY_SECRET_KEY: ${GRAFANA_SECRET_KEY}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-worldmap-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/prod-dashboards:/etc/grafana/provisioning/dashboards
      - ./docker/grafana/prod-datasources:/etc/grafana/provisioning/datasources
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Log Aggregation with Fluentd
  fluentd:
    image: fluent/fluentd:v1.16-debian-1
    restart: unless-stopped
    volumes:
      - ./docker/fluentd/fluent.conf:/fluentd/etc/fluent.conf
      - ./storage/logs:/var/log/app
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    networks:
      - interviews-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Backup Service
  backup:
    image: alpine:latest
    restart: "no"
    volumes:
      - database_data:/data/mysql
      - redis_data:/data/redis
      - ./backups:/backups
      - ./docker/scripts/backup.sh:/backup.sh
    environment:
      - DB_HOST=database
      - DB_USER=root
      - DB_PASSWORD=${DB_ROOT_PASSWORD}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - BACKUP_S3_BUCKET=${BACKUP_S3_BUCKET}
    networks:
      - interviews-network
    command: /backup.sh
    profiles:
      - backup

  # SSL Certificate Management
  certbot:
    image: certbot/certbot:latest
    restart: "no"
    volumes:
      - ./docker/ssl:/etc/letsencrypt
      - ./web/dist:/var/www/html
    command: certonly --webroot --webroot-path=/var/www/html --email ${SSL_EMAIL} --agree-tos --no-eff-email -d ${DOMAIN_NAME}
    profiles:
      - ssl

# Production-specific volumes
volumes:
  database_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/mysql
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/redis
  elasticsearch_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/elasticsearch
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/prometheus
  grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/grafana
